{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LVz8rj4tsBX",
    "outputId": "7fce0bfe-9605-466b-ac96-a5f2c3ba8bb3"
   },
   "outputs": [],
   "source": [
    "#Importing all the required libraries and packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2                 \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle \n",
    "from tqdm import tqdm      \n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1q_d8GJ-vv2C"
   },
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "\n",
    "TRAIN_DIR = 'C:/Users/hp/Desktop/Project/PlantDiseaseDetection/Dataset/TrainForVGG'\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDOdDJVRxWiX",
    "outputId": "1e2da3ba-599e-4c32-c84d-df4ff192be5b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 400/400 [00:02<00:00, 141.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "\n",
    "labels = []\n",
    "def label_img(img):\n",
    "    word_label = img[0]\n",
    "    if word_label == 'h': return 0\n",
    "    elif word_label == 'b': return 1\n",
    "    elif word_label == 'v': return 2\n",
    "    elif word_label == 'l': return 3\n",
    "\n",
    "    \n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    IMG_SIZE = 224\n",
    "    \n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img[0])\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append(np.array(img))\n",
    "        labels.append(label)\n",
    "    return training_data\n",
    "\n",
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1DFaqcySyAJp"
   },
   "outputs": [],
   "source": [
    "#Converting lists to numpy arrays\n",
    "\n",
    "data = np.array(train_data)\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMouAuOBPBcD",
    "outputId": "f891796c-a2d9-4fb9-9d85-3e0747ea1827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data :(400, 224, 224, 3)\n",
      "Shape of labels :(400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data :\" + str(data.shape))\n",
    "print(\"Shape of labels :\" + str(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "W5CjH3Npx9Ow"
   },
   "outputs": [],
   "source": [
    "#Splitting data into train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QbUl2T2LyitR"
   },
   "outputs": [],
   "source": [
    "#Converting label lists to categorical form \n",
    "\n",
    "y_train = to_categorical(y_train, 4)\n",
    "\n",
    "y_test = to_categorical(y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k_O85Lb0yzm4"
   },
   "outputs": [],
   "source": [
    "#Classifier Construction\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jav1sfIzy_XP"
   },
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhJ0Lt2U1Qhr",
    "outputId": "a61683a1-3c33-4674-ef14-c01954a3cf39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 16388     \n",
      "=================================================================\n",
      "Total params: 134,276,932\n",
      "Trainable params: 134,276,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Analysing the structure of VGG model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R_qlLadG1aMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 376s 34s/step - loss: 2117.0841 - accuracy: 0.3100 - val_loss: 4.0673 - val_accuracy: 0.2250\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 200s 20s/step - loss: 2.0536 - accuracy: 0.2726 - val_loss: 1.3839 - val_accuracy: 0.2250\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 198s 20s/step - loss: 1.5503 - accuracy: 0.3002 - val_loss: 1.3829 - val_accuracy: 0.3250\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 196s 20s/step - loss: 1.3922 - accuracy: 0.2274 - val_loss: 1.3839 - val_accuracy: 0.3250\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 195s 20s/step - loss: 1.3889 - accuracy: 0.1867 - val_loss: 1.3871 - val_accuracy: 0.2250\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 196s 20s/step - loss: 1.3868 - accuracy: 0.2692 - val_loss: 1.3880 - val_accuracy: 0.2250\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 198s 20s/step - loss: 1.4085 - accuracy: 0.2554 - val_loss: 7.0409 - val_accuracy: 0.2250\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 198s 20s/step - loss: 3.1137 - accuracy: 0.2535 - val_loss: 1.3884 - val_accuracy: 0.2250\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 197s 20s/step - loss: 1.3840 - accuracy: 0.2916 - val_loss: 1.3899 - val_accuracy: 0.2250\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 2433s 268s/step - loss: 1.3825 - accuracy: 0.2752 - val_loss: 1.3899 - val_accuracy: 0.2250\n"
     ]
    }
   ],
   "source": [
    "#Fitting the data into model\n",
    "\n",
    "epochs = 10\n",
    "hist = model.fit(X_train, y_train, steps_per_epoch=10, epochs=epochs, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "model.save(\"vgg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy of the model is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25218750089406966"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average accuracy of train data\n",
    "\n",
    "print(\"The train accuracy of the model is\")\n",
    "np.mean(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of the model is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24499999284744262"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average accuracy of validation data\n",
    "\n",
    "print(\"The test accuracy of the model is\")\n",
    "np.mean(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) (320,)\n",
      "[1 1 3 3 3] [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Train_Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict \n",
    "pred = model.predict(X_train, batch_size = 32)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "y_train = np.argmax(y_train, axis = 1)\n",
    "print(y_train.shape, pred.shape)\n",
    "print(y_train[:5], pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.41        82\n",
      "           1       0.00      0.00      0.00        74\n",
      "           2       0.00      0.00      0.00        82\n",
      "           3       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.26       320\n",
      "   macro avg       0.06      0.25      0.10       320\n",
      "weighted avg       0.07      0.26      0.10       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,) (80,)\n",
      "[3 3 1 3 1] [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Test_Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# predict \n",
    "pred = model.predict(X_test, batch_size = 32)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "print(y_test.shape, pred.shape)\n",
    "print(y_test[:5], pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.37        18\n",
      "           1       0.00      0.00      0.00        26\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.23        80\n",
      "   macro avg       0.06      0.25      0.09        80\n",
      "weighted avg       0.05      0.23      0.08        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\hp\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
